为什么会出现：随着网络越来越深，梯度可能会爆炸或消失，采用一定方法收敛之后收敛了，但是精度会变差

怎么实现的：





------

梯度爆炸或消失解决方法：加BN之类的或权重在初始化的时候不能太大也不能太小

精度变差的原因：并不是过拟合，是因为训练误差和测试误差都变得很高



overfitting（过拟合）：训练误差变得很低，但测试误差变得很高



网络加层之后精度还有可能变差

identity mapping[恒等映射]：输入输出一一对应

亮点：提出了一个结构使深的网络精度不会比浅的网络精度差

