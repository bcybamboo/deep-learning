### 备赛历程中的飞浆学习路线

- #### 首先要了解赛题的具体内容，从而确定下一步学习的方向。

这一步是必不可少的。这次的赛题是基于百度飞浆的3D医疗数据智能解析平台，要求就是医学影像分割。所以下一步要学习paddle paddle的框架，关于医学影像分割的模型，以及了解医学影像数据集中的图片格式，以此来判断使用哪种初始化方法，一步一步拆解任务然后去学习相关的。

- #### 第一，想要学习paddle paddle框架，必定需要配置环境。

  首先在minconda创建虚拟环境，检查自己电脑可以安装CUDA驱动的版本，接着去安装CUDA的驱动以及CUDNN，然后进入飞浆官网选择适合自己电脑配置的版本，复制官网提示的命令安装，如果嫌下载太慢了，可以换源。安装好之后检查是否安装成功，等成功之后就可以在pycharm中找到配置好的环境就可以使用了。

- #### 第二，学习paddlepaddle框架。

  我一开始从网上找教程学，paddle官网里就有完整的使用指南，飞浆还是很让人惊喜的。

  首先给了一个手写数字识别任务上手，然后使用模型中的各个板块对paddlepaddle进行解释和学习。先介绍了张量，然后到数据集定义与加载，数据预处理，模型组网，再到模型训练、评估与推理，最后是模型保存与加载。简单的跟着教程过了一遍，熟悉了不少。

- #### 第三，我又跟着飞浆课程里的《图像分割7日打卡营》开始学习。

  从基础开始一点一点学，了解好有关aistdio中notebook操作和如何debug，就开始paddleseg快速体验，然后了解分割的各种类型。

  ![image-20230304085716666](C:\Users\bamboo\AppData\Roaming\Typora\typora-user-images\image-20230304085716666.png)

  然后就直接用实例来逐步逐步的了解，后面介绍了FCN网络还有U-Net和PSPNet模型，还有有关DeepLab等，内容丰富，对图像分割了解得更深入。

- #### 第四，开始看有关nnunet的论文，进一步的了解。

  学习nnunet之前要先了解unet，vnet等框架，unet是nnunet的基础。

  nnunet是一种鲁棒的基于2Dunet和3Dunet的自适应框架，作者认为结构修改的越多，越容易过拟合，更应该关注于能提高模型性能和泛化性的其他方面，最好把重心放在：预处理（resamping和normalization）、训练（loss、optimizer设置、数据增广）、推理（patch-based策略、test-time-augmentations集成和模型集成等）、后处理（如增强单连通域等）。而且在医疗影像中，预处理和后处理的作用有时候大于网络本身的改造。所以nnunet做了一些微小的修改，将relu换成了leaky relu，这样解决了神经元死亡的问题；将batch norm换成instance norm，在医学图像3D分割中，如果我们使用多中心的数据，由于数据比较少，且多个中心的数据之间本来就存在差异，那么用Batchnorm得不偿失，因为滑动平均均值方差是在训练集上计算的，而测试的数据跟训练集又不一样，所以得到的效果就是在训练集上收敛很快，但在测试集上效果很差。而Instancenorm是独立于batchsize的，所以训练的时候只需要两个参数就是minibatch的均值方差，测试的时候也不需要滑动平均均值方差了。

- #### 第五，开始尝试单折训练。

  一开始通过跑baseline1 来熟悉aistdio的操作，怎么运行、怎么数据预处理、怎么开始训练、怎么推理、怎么提交结果，都是从这学到的。baseline1使用的网络是vnet。vnet是基于unet的改进网络，为了改进unet的一些不足，提出了一些创新点。第一个创新点就是引入了残差，在每个stage中，Vnet采用了Resnet的element-wise;第二个创新点就是使用卷积层代替上采样和下采样的池化层。
  
  然后就开始跑baseline2,这是使用nnunet cascade lowres实现的高精度模型。先把baseline2跑通了，然后开始改进。我们尝试了增大迭代次数来提高准确率，从初始增大到6万代开始尝试，发现准确率确实提升了，然后就增大到18万代，准确率也提升了，然后就开始尝试多折训练。
  
  #### 第六，开始跑多折训练。
  
  
  
   
